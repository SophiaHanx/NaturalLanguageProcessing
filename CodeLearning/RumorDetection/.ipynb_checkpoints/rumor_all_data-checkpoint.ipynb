{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  将数据格式化为 'y x'，写入all_data.txt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#解压原始数据集，将Chinese_Rumor_Dataset-master.zip解压\n",
    "import zipfile\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "src_path=\"./data/Chinese_Rumor_Dataset-master.zip\"\n",
    "target_path=\"./data/Chinese_Rumor_Dataset-master\"\n",
    "if(not os.path.isdir(target_path)):\n",
    "    z = zipfile.ZipFile(src_path, 'r')\n",
    "    z.extractall(path=target_path)\n",
    "    z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别为谣言数据、非谣言数据、全部数据的文件路径\n",
    "rumor_class_dirs = os.listdir(target_path + \"/CED_Dataset/rumor-repost/\")\n",
    "non_rumor_class_dirs = os.listdir(target_path + \"/CED_Dataset/non-rumor-repost/\")\n",
    "original_microblog = target_path + \"/CED_Dataset/original-microblog/\"\n",
    "\n",
    "# 谣言标签为0，非谣言标签为1\n",
    "rumor_label = \"0\"\n",
    "non_rumor_label = \"1\"\n",
    "\n",
    "# 分别统计谣言数据与非谣言数据的总数\n",
    "rumor_num = 0\n",
    "non_rumor_num = 0\n",
    "\n",
    "all_rumor_list = []\n",
    "all_non_rumor_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "谣言数据总量为：1538\n",
      "非谣言数据总量为：1849\n"
     ]
    }
   ],
   "source": [
    "# 解析谣言数据\n",
    "for rumor_class_dir in rumor_class_dirs:\n",
    "    if (rumor_class_dir != '.DS_Store'):\n",
    "        # 遍历谣言数据，并解析\n",
    "        with open(original_microblog + rumor_class_dir, 'r',encoding='UTF-8') as f:\n",
    "            rumor_content = f.read()\n",
    "        rumor_dict = json.loads(rumor_content)\n",
    "        all_rumor_list.append(rumor_label + \"\\t\" + rumor_dict[\"text\"] + \"\\n\")\n",
    "        rumor_num += 1\n",
    "\n",
    "# 解析非谣言数据\n",
    "for non_rumor_class_dir in non_rumor_class_dirs:\n",
    "    if (non_rumor_class_dir != '.DS_Store'):\n",
    "        with open(original_microblog + non_rumor_class_dir, 'r',encoding='UTF-8') as f2:\n",
    "            non_rumor_content = f2.read()\n",
    "        non_rumor_dict = json.loads(non_rumor_content)\n",
    "        all_non_rumor_list.append(non_rumor_label + \"\\t\" + non_rumor_dict[\"text\"] + \"\\n\")\n",
    "        non_rumor_num += 1\n",
    "\n",
    "print(\"谣言数据总量为：\" + str(rumor_num))\n",
    "print(\"非谣言数据总量为：\" + str(non_rumor_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总量为：3387\n"
     ]
    }
   ],
   "source": [
    "print(\"数据总量为：\" + str(rumor_num+non_rumor_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全部数据进行乱序后写入all_data.txt\n",
    "\n",
    "data_list_path = \"./data/\"\n",
    "all_data_path = data_list_path + \"all_data.txt\"\n",
    "\n",
    "all_data_list = all_rumor_list + all_non_rumor_list\n",
    "\n",
    "random.shuffle(all_data_list)\n",
    "\n",
    "# 在生成all_data.txt之前，首先将其清空\n",
    "with open(all_data_path, 'w') as f:\n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "\n",
    "with open(all_data_path, 'a',encoding='UTF-8') as f:\n",
    "    for data in all_data_list:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TF2.1]",
   "language": "python",
   "name": "conda-env-TF2.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
